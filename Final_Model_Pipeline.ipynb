{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c589c01",
   "metadata": {},
   "source": [
    "### Predict Forest Classification on New Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339afac1",
   "metadata": {},
   "source": [
    "This notebook will load in the saved model that used transfer learning with MobileNetV2 wit the top 14 layers fine-tuned to the training images. Then you can predict the classification for an entire directory containing image files. The output is a list of tuples with each image's file name and it's predicted classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5746a9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "92ea05d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model = keras.models.load_model(\"Forest_MobileNetV2_Transfer_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "856ee9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " tf.math.truediv (TFOpLambda  (None, 64, 64, 3)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " tf.math.subtract (TFOpLambd  (None, 64, 64, 3)        0         \n",
      " a)                                                              \n",
      "                                                                 \n",
      " mobilenetv2_1.00_224 (Funct  (None, 2, 2, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1280)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1280)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 1281      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,259,265\n",
      "Trainable params: 1,041,281\n",
      "Non-trainable params: 1,217,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "reconstructed_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cdc38db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = 3 #RGB\n",
    "img_w = 64\n",
    "img_h = 64\n",
    "input_shape = (img_h, img_w, channels)\n",
    "directory = \"../additional_images_for_testing/mixed_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "725f9b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('desert_1.jpg', 'NoTrees'), ('desert_10.jpg', 'Trees'), ('desert_11.jpg', 'Trees'), ('desert_12.jpg', 'Trees'), ('desert_13.jpg', 'Trees'), ('desert_14.jpg', 'Trees'), ('desert_15.jpg', 'Trees'), ('desert_16.jpg', 'Trees'), ('desert_2.jpg', 'NoTrees'), ('desert_3.jpg', 'Trees'), ('desert_4.jpg', 'NoTrees'), ('desert_5.jpg', 'Trees'), ('desert_6.jpg', 'Trees'), ('desert_7.jpg', 'NoTrees'), ('desert_8.jpg', 'Trees'), ('desert_9.jpg', 'Trees'), ('Forest_2.jpg', 'Trees'), ('Forest_20.jpg', 'Trees'), ('Forest_21.jpg', 'NoTrees'), ('Forest_22.jpg', 'Trees'), ('Forest_23.jpg', 'Trees'), ('Forest_29.jpg', 'Trees'), ('Forest_3.jpg', 'Trees'), ('Forest_30.jpg', 'Trees'), ('Forest_31.jpg', 'Trees'), ('Forest_32.jpg', 'Trees'), ('Forest_4.jpg', 'Trees'), ('Forest_5.jpg', 'Trees'), ('Forest_6.jpg', 'Trees'), ('Forest_7.jpg', 'Trees'), ('Forest_8.jpg', 'Trees'), ('Forest_9.jpg', 'Trees'), ('SeaLake_1.jpg', 'NoTrees'), ('SeaLake_11.jpg', 'NoTrees'), ('SeaLake_16.jpg', 'NoTrees'), ('SeaLake_18.jpg', 'NoTrees'), ('SeaLake_2.jpg', 'NoTrees'), ('SeaLake_20.jpg', 'NoTrees'), ('SeaLake_21.jpg', 'NoTrees'), ('SeaLake_3.jpg', 'NoTrees'), ('SeaLake_31.jpg', 'NoTrees'), ('SeaLake_33.jpg', 'NoTrees'), ('SeaLake_35.jpg', 'NoTrees'), ('SeaLake_36.jpg', 'NoTrees'), ('SeaLake_37.jpg', 'NoTrees'), ('SeaLake_7.jpg', 'NoTrees'), ('SeaLake_8.jpg', 'NoTrees'), ('SeaLake_9.jpg', 'NoTrees')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "predicted_classes = []\n",
    "image_files = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    if os.path.isfile(f):\n",
    "        test_img = keras.preprocessing.image.load_img(f, target_size=(img_w,img_h))\n",
    "\n",
    "        img_array = keras.preprocessing.image.img_to_array(test_img)\n",
    "        img_array = tf.expand_dims(img_array, axis=0)  # Create batch axis\n",
    "\n",
    "        class_names = ['NoTrees', 'Trees']\n",
    "\n",
    "        prediction = reconstructed_model.predict(img_array, verbose=0)\n",
    "        prediction = tf.nn.sigmoid(prediction)\n",
    "        prediction = tf.where(prediction < 0.5, 0, 1)\n",
    "        \n",
    "        #print(filename)\n",
    "        image_files.append(filename)\n",
    "        \n",
    "        if prediction[0] == 0:\n",
    "            #print(class_names[0])\n",
    "            predicted_classes.append(class_names[0])\n",
    "        else: \n",
    "            #print(class_names[1])\n",
    "            predicted_classes.append(class_names[1])\n",
    "\n",
    "merged_list = list(zip(image_files, predicted_classes))            \n",
    "print(merged_list)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4451566",
   "metadata": {},
   "source": [
    "These are from a different set of satellite images, and the model does a good job on the Forest images and on the SeaLake images, but has a little trouble with some of the Desert images, as there were none like this in the training data. I threw those in there to see how it would do. It is not likely that one would needing to classify whether desert images are forested or not, so it's not a huge problem that the model does not work well here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forestCNN",
   "language": "python",
   "name": "forestcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
